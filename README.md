# ğŸ¥ VideoChat - AI-Powered Video Processing Platform

<div align="center">

![VideoChat](https://img.shields.io/badge/VideoChat-AI%20Powered-blue)
![Node.js](https://img.shields.io/badge/Node.js-18+-green)
![React](https://img.shields.io/badge/React-19-blue)
![MongoDB](https://img.shields.io/badge/MongoDB-Latest-brightgreen)

**Upload videos, generate transcripts, and get AI-powered summaries at any timestamp**

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Architecture](#-architecture) â€¢ [API Docs](#-api-documentation)

</div>

---

## âœ¨ Features

- ğŸ¬ **Video Upload** - Upload videos to Cloudinary with metadata
- ğŸ¤ **Automatic Transcription** - OpenAI Whisper API for accurate transcript generation
- ğŸ“ **Semantic Chunking** - Intelligent text segmentation (80-140 words per chunk)
- ğŸ” **Vector Search** - MongoDB Atlas vector search for semantic similarity
- ğŸ’¬ **AI Chat** - Ask questions about video content with context-aware answers
- ğŸ¤– **AI Summaries** - Google Gemini-powered summaries (short/medium/detailed)
- âš¡ **Background Processing** - BullMQ queue system for async video processing
- ğŸ’¾ **Smart Caching** - Summary caching to reduce API calls
- ğŸ¨ **Modern UI** - Beautiful React + Tailwind CSS interface with chat modal

---

## ğŸ—ï¸ Architecture

### System Overview

```mermaid
graph TB
    subgraph Frontend["ğŸ–¥ï¸ Frontend (React + Tailwind)"]
        UI[Upload Page]
        Summary[Summary Page]
        Store[Zustand Store]
    end

    subgraph Backend["âš™ï¸ Backend (Node.js + Express)"]
        API[Express API Server]
        UploadCtrl[Upload Controller]
        SummaryCtrl[Summary Controller]
    end

    subgraph Storage["ğŸ’¾ Storage & Database"]
        Cloudinary[Cloudinary<br/>Video Storage]
        MongoDB[(MongoDB<br/>Video, Transcript,<br/>Chunk, Summary)]
    end

    subgraph Queue["ğŸ”„ Queue System"]
        Redis[(Redis<br/>BullMQ Queue)]
        Worker[Worker Process]
    end

    subgraph AI["ğŸ¤– AI Services"]
        Whisper[OpenAI Whisper<br/>Transcription]
        Gemini[Google Gemini<br/>Summarization]
    end

    UI -->|POST /upload| API
    Summary -->|POST /summary| API
    Store -->|State Management| UI
    Store -->|State Management| Summary

    API --> UploadCtrl
    API --> SummaryCtrl

    UploadCtrl -->|Upload Video| Cloudinary
    UploadCtrl -->|Save Metadata| MongoDB
    UploadCtrl -->|Enqueue Job| Redis

    Redis -->|Process Job| Worker
    Worker -->|Download Video| Cloudinary
    Worker -->|Transcribe| Whisper
    Worker -->|Save Transcripts| MongoDB
    Worker -->|Generate Chunks| MongoDB
    Worker -->|Update Status| MongoDB

    SummaryCtrl -->|Find Chunk| MongoDB
    SummaryCtrl -->|Generate Summary| Gemini
    SummaryCtrl -->|Cache Summary| MongoDB

    style Frontend fill:#e1f5ff
    style Backend fill:#fff4e1
    style Storage fill:#e8f5e9
    style Queue fill:#f3e5f5
    style AI fill:#ffe0e0
```

---

## ğŸ“Š Data Flow

### 1ï¸âƒ£ Video Upload Flow

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant API
    participant Cloudinary
    participant MongoDB
    participant Queue

    User->>Frontend: Upload video + metadata
    Frontend->>API: POST /api/v1/video/upload
    API->>Cloudinary: Upload video file
    Cloudinary-->>API: Return video URL
    API->>MongoDB: Create Video (status: processing)
    API->>Queue: Enqueue 'process-video' job
    API-->>Frontend: Return video data
    Frontend-->>User: Show success message
```

### 2ï¸âƒ£ Background Processing Flow

```mermaid
sequenceDiagram
    participant Queue
    participant Worker
    participant Cloudinary
    participant Whisper
    participant MongoDB

    Queue->>Worker: Job 'process-video' {videoId}
    Worker->>MongoDB: Fetch Video document
    MongoDB-->>Worker: Video data
    
    Worker->>Cloudinary: Download video
    Cloudinary-->>Worker: Video file
    Worker->>Worker: Extract audio (ffmpeg)
    Worker->>Whisper: Transcribe audio
    Whisper-->>Worker: Transcript segments
    Worker->>MongoDB: Save Transcript documents
    
    Worker->>MongoDB: Fetch Transcript segments
    MongoDB-->>Worker: Segments data
    Worker->>Worker: Generate semantic chunks
    Worker->>MongoDB: Save Chunk documents
    
    Worker->>MongoDB: Update Video status = 'ready'
    Worker->>Queue: Job completed
```

### 3ï¸âƒ£ Summary Generation Flow

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant API
    participant MongoDB
    participant Gemini

    User->>Frontend: Request summary (videoId, timestamp, type)
    Frontend->>API: POST /api/v1/video/summary
    API->>MongoDB: Find Chunk for timestamp
    MongoDB-->>API: Chunk data
    
    API->>MongoDB: Check Summary cache
    alt Cache Hit
        MongoDB-->>API: Existing summary
        API-->>Frontend: Return cached summary
    else Cache Miss
        API->>Gemini: Generate summary (chunk.text, type)
        Gemini-->>API: Summary text
        API->>MongoDB: Save Summary
        API-->>Frontend: Return new summary
    end
    
    Frontend-->>User: Display summary
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** v18+ 
- **MongoDB Atlas** (required for vector search)
- **Redis** (for BullMQ)
- **FFmpeg** (for audio extraction)
- **API Keys**: OpenAI, Google Gemini, Cloudinary

### Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd VideoChat

# Install server dependencies
cd server
npm install

# Install client dependencies
cd ../client
npm install
```

### Environment Setup

**Server** (`server/.env`):
```env
# MongoDB
MONGODB_URI=mongodb://localhost:27017/videochat

# Redis
REDIS_HOST=127.0.0.1
REDIS_PORT=6379

# Cloudinary
CLOUDDINARY_CLOUD_NAME=your_cloud_name
CLOUDDINARY_API_KEY=your_api_key
CLOUDDINARY_API_SECRET=your_api_secret

# OpenAI (Whisper)
OPENAI_API_KEY=your_openai_key

# Google Gemini
GOOGLE_GENERATIVE_AI_API_KEY=your_google_key

# Optional
PORT=3000
CLEAN_QUEUE_ON_STARTUP=false
FRONTEND_URL=http://localhost:5173
```

**Client** (`client/.env`):
```env
VITE_API_URL=http://localhost:3000/api/v1/video
```

### Running the Application

You need **3 terminal windows**:

**Terminal 1 - Server:**
```bash
cd server
npm run dev
```

**Terminal 2 - Worker:**
```bash
cd server
npm run worker
```

**Terminal 3 - Client:**
```bash
cd client
npm run dev
```

### Verify Installation

```bash
# Check FFmpeg
cd server
npm run check-ffmpeg

# Check MongoDB connection (should see "Connected to MongoDB")
# Check Redis (should see worker connected)
```

### Setup Vector Search Index

**Important:** Before using the chat feature, you must create a vector search index in MongoDB Atlas.

See [VECTOR_INDEX_SETUP.md](./VECTOR_INDEX_SETUP.md) for detailed instructions.

Quick setup:
1. Go to MongoDB Atlas â†’ Search â†’ Create Search Index
2. Use JSON Editor and paste the configuration from `VECTOR_INDEX_SETUP.md`
3. Name it `vector_index` and select your `chunks` collection
4. Wait for the index to become active

### Generate Embeddings for Existing Chunks

If you have existing chunks without embeddings, run:

```bash
cd server
node scripts/generate-embeddings.js [videoId]
```

Omit `videoId` to process all chunks without embeddings.

---

## ğŸ“ Project Structure

```
VideoChat/
â”œâ”€â”€ server/                    # Backend (Node.js + Express)
â”‚   â”œâ”€â”€ controllers/          # API controllers
â”‚   â”‚   â”œâ”€â”€ video.controller.js
â”‚   â”‚   â”œâ”€â”€ transcript.controller.js
â”‚   â”‚   â”œâ”€â”€ chunk.controller.js
â”‚   â”‚   â”œâ”€â”€ summary.controller.js
â”‚   â”‚   â””â”€â”€ chat.controller.js
â”‚   â”œâ”€â”€ modals/               # Mongoose models
â”‚   â”‚   â”œâ”€â”€ video.modal.js
â”‚   â”‚   â”œâ”€â”€ transcript.modal.js
â”‚   â”‚   â”œâ”€â”€ chunk.modal.js
â”‚   â”‚   â”œâ”€â”€ summery.modal.js
â”‚   â”‚   â””â”€â”€ chat.modal.js
â”‚   â”œâ”€â”€ routes/               # Express routes
â”‚   â”‚   â””â”€â”€ video.routes.js
â”‚   â”œâ”€â”€ queue/                # BullMQ queue
â”‚   â”‚   â””â”€â”€ video.queue.js
â”‚   â”œâ”€â”€ workers/              # Background workers
â”‚   â”‚   â””â”€â”€ video.worker.js
    â”‚   â”œâ”€â”€ lib/                  # Utilities
    â”‚   â”‚   â”œâ”€â”€ db.js
    â”‚   â”‚   â”œâ”€â”€ cloudinary.js
    â”‚   â”‚   â”œâ”€â”€ multer.js
    â”‚   â”‚   â”œâ”€â”€ videoMetadata.js
    â”‚   â”‚   â””â”€â”€ embeddings.js
    â”‚   â”œâ”€â”€ scripts/              # Utility scripts
    â”‚   â”‚   â”œâ”€â”€ reset-queue.js
    â”‚   â”‚   â”œâ”€â”€ generate-embeddings.js
    â”‚   â”‚   â””â”€â”€ clear-database.js
â”‚   â””â”€â”€ index.js              # Server entry point
â”‚
â””â”€â”€ client/                    # Frontend (React + Vite)
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ pages/            # React pages
    â”‚   â”‚   â”œâ”€â”€ UploadPage.jsx
    â”‚   â”‚   â””â”€â”€ SummaryPage.jsx
    â”‚   â”œâ”€â”€ components/       # React components
    â”‚   â”‚   â””â”€â”€ ChatModal.jsx
    â”‚   â”œâ”€â”€ store/            # Zustand stores
    â”‚   â”‚   â””â”€â”€ useVideoStore.js
    â”‚   â”œâ”€â”€ api/              # API client
    â”‚   â”‚   â””â”€â”€ videoApi.js
    â”‚   â””â”€â”€ App.jsx
    â””â”€â”€ package.json
```

---

## ğŸ”Œ API Documentation

### Upload Video

**Endpoint:** `POST /api/v1/video/upload`

**Request:**
```javascript
FormData {
  file: File,           // Video file
  title: string,       // Video title
  description: string   // Optional description
  // Duration is extracted automatically from the video file
}
```

**Response:**
```json
{
  "message": "Video uploaded successfully. Processing has started.",
  "data": {
    "_id": "video_id",
    "title": "Video Title",
    "description": "Description",
    "videoUrl": "https://cloudinary.com/...",
    "duration": 120,
    "status": "processing"
  }
}
```

### Get Video Status

**Endpoint:** `GET /api/v1/video/:videoId`

**Response:**
```json
{
  "message": "Video retrieved successfully",
  "data": {
    "_id": "video_id",
    "title": "Video Title",
    "status": "ready",  // processing | ready | failed
    "videoUrl": "https://...",
    "duration": 120
  }
}
```

### Generate Summary

**Endpoint:** `POST /api/v1/video/summary`

**Request:**
```json
{
  "videoId": "video_id",
  "timestamp": 45.5,    // Time in seconds
  "type": "medium"      // short | medium | detailed
}
```

**Response:**
```json
{
  "message": "Summary generated successfully",
  "data": {
    "chunkId": "chunk_id",
    "type": "medium",
    "summary": "Generated summary text..."
  }
}
```

### Chat with Video

**Endpoint:** `POST /api/v1/video/chat`

**Request:**
```json
{
  "videoId": "video_id",
  "question": "Explain backpropagation in this video"
}
```

**Response:**
```json
{
  "message": "Chat response generated successfully",
  "data": {
    "answer": "Backpropagation is a method used to train neural networks...",
    "timestamps": [
      {
        "start": 120.5,
        "end": 145.2,
        "formatted": "2:00 - 2:25"
      }
    ],
    "chunks": [
      {
        "start": 120.5,
        "end": 145.2,
        "text": "Chunk text content..."
      }
    ]
  }
}
```

### Get Chat History

**Endpoint:** `GET /api/v1/video/:videoId/chat`

**Response:**
```json
{
  "message": "Chat history retrieved successfully",
  "data": [
    {
      "_id": "chat_id",
      "videoId": "video_id",
      "question": "What is machine learning?",
      "answer": "Machine learning is...",
      "chunks": [...],
      "createdAt": "2024-01-01T00:00:00.000Z"
    }
  ]
}
```

### Delete Chat History

**Endpoint:** `DELETE /api/v1/video/:videoId/chat`

**Response:**
```json
{
  "message": "Chat history deleted successfully"
}
```

---

## ğŸ› ï¸ Available Scripts

### Server Scripts

```bash
npm run dev          # Start server with nodemon
npm start            # Start server (production)
npm run worker       # Start worker process
npm run dev:worker   # Start worker with nodemon
npm run reset-queue  # Reset/clear queue
npm run clear-db     # Clear all database data (with confirmation)
npm run clear-db:force # Clear all database data (skip confirmation)
npm run check-ffmpeg # Verify FFmpeg installation
```

### Client Scripts

```bash
npm run dev          # Start dev server
npm run build        # Build for production
npm run preview      # Preview production build
```

---

## ğŸ”„ Queue Management

### Reset Queue

If jobs get stuck, reset the queue:

```bash
cd server
npm run reset-queue
```

### Auto-clean on Startup

Add to `server/.env`:
```env
CLEAN_QUEUE_ON_STARTUP=true
```

### Queue Statistics

The reset script shows:
- Waiting jobs
- Active jobs
- Completed jobs
- Failed jobs

---

## ğŸ¯ Processing Pipeline

### Step-by-Step Processing

1. **Upload** â†’ Video uploaded to Cloudinary
2. **Queue** â†’ Job added to BullMQ queue
3. **Download** â†’ Worker downloads video from Cloudinary
4. **Extract Audio** â†’ FFmpeg extracts audio track
5. **Transcribe** â†’ OpenAI Whisper generates transcript segments
6. **Chunk** â†’ Semantic chunking (80-140 words, topic detection)
7. **Embed** â†’ Generate embeddings for all chunks using OpenAI
8. **Store** â†’ Transcripts and chunks (with embeddings) saved to MongoDB
9. **Ready** â†’ Video status updated to "ready"

### Chunking Logic

Chunks are created based on:
- **Word Count**: 80-140 words per chunk
- **Pauses**: Split on pauses > 2 seconds
- **Topic Changes**: Phrases like "next", "moving on", "now let's"
- **Sentence Endings**: Natural breaks at periods/exclamation marks

---

## ğŸ› Troubleshooting

### Common Issues

**FFmpeg Not Found**
```bash
# Check installation
npm run check-ffmpeg

# Install on Windows
winget install ffmpeg
# or
choco install ffmpeg
```

**MongoDB Connection Error**
- Verify MongoDB is running
- Check `MONGODB_URI` in `.env`
- Ensure connection string is correct

**Redis Connection Error**
- Verify Redis is running: `redis-cli ping`
- Check `REDIS_HOST` and `REDIS_PORT` in `.env`

**Worker Not Processing Jobs**
- Ensure worker is running in separate terminal
- Check Redis connection
- Verify MongoDB connection in worker
- Check worker logs for errors

**Queue Jobs Stuck**
```bash
# Reset the queue
npm run reset-queue
```

---

## ğŸ“Š Database Models

### Video
```javascript
{
  title: String,
  description: String,
  videoUrl: String,
  duration: Number,
  status: "processing" | "ready" | "failed",
  createdAt: Date,
  updatedAt: Date
}
```

### Transcript
```javascript
{
  videoId: ObjectId,
  start: Number,    // seconds
  end: Number,      // seconds
  text: String,
  createdAt: Date
}
```

### Chunk
```javascript
{
  videoId: ObjectId,
  start: Number,    // seconds
  end: Number,      // seconds
  text: String,
  embedding: [Number],  // 1536-dimensional vector
  createdAt: Date
}
```

### Chat
```javascript
{
  videoId: ObjectId,
  question: String,
  answer: String,
  chunks: [{
    chunkId: ObjectId,
    start: Number,
    end: Number,
    text: String
  }],
  createdAt: Date
}
```

### Summary
```javascript
{
  chunkId: ObjectId,
  type: "short" | "medium" | "detailed",
  summaryText: String,
  createdAt: Date
}
```

---

## ğŸ” Environment Variables Reference

| Variable | Description | Required | Default |
|----------|-------------|----------|---------|
| `MONGODB_URI` | MongoDB connection string | âœ… | - |
| `REDIS_HOST` | Redis host | âŒ | `127.0.0.1` |
| `REDIS_PORT` | Redis port | âŒ | `6379` |
| `REDIS_PASSWORD` | Redis password | âŒ | - |
| `CLOUDDINARY_CLOUD_NAME` | Cloudinary cloud name | âœ… | - |
| `CLOUDDINARY_API_KEY` | Cloudinary API key | âœ… | - |
| `CLOUDDINARY_API_SECRET` | Cloudinary API secret | âœ… | - |
| `OPENAI_API_KEY` | OpenAI API key (Whisper + Embeddings) | âœ… | - |
| `GOOGLE_GENERATIVE_AI_API_KEY` | Google Gemini API key | âœ… | - |
| `PORT` | Server port | âŒ | `3000` |
| `CLEAN_QUEUE_ON_STARTUP` | Auto-clean queue | âŒ | `false` |
| `FRONTEND_URL` | Frontend URL for CORS | âŒ | `http://localhost:5173` |
| `VITE_API_URL` | API base URL (client) | âŒ | `http://localhost:3000/api/v1/video` |

---

## ğŸ¨ Tech Stack

### Backend
- **Node.js** - Runtime environment
- **Express** - Web framework
- **MongoDB** - Database
- **Mongoose** - ODM
- **BullMQ** - Queue system
- **Redis** - Queue storage
- **Cloudinary** - Video storage
- **Multer** - File upload handling
- **OpenAI** - Whisper transcription + Embeddings
- **Google Gemini** - AI summarization
- **MongoDB Atlas** - Vector search for semantic similarity

### Frontend
- **React** - UI framework
- **Vite** - Build tool
- **Tailwind CSS** - Styling
- **Zustand** - State management
- **Axios** - HTTP client

---

## ğŸ“ License

This project is licensed under the ISC License.

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“§ Support

For issues and questions, please open an issue on GitHub.

---

<div align="center">

**Made with â¤ï¸ using Node.js, React, and AI**

[â¬† Back to Top](#-videochat---ai-powered-video-processing-platform)

</div>
